## 리뷰
## 주요 진행 활동
- spark 최적화 및 모니터링 강의
- 다노님 피드백
- EMR transform 스크립트 구성
- gpt api 구성
- Extract 전체 과정 테스트

## 새롭게 알게 된 내용

### Catalyst Optimizer
This is a rule based engine.</br>
It takes the logical plan(우리가 짠 코드) → Optimized Physical Plan(실제 실행 계획)</br>

Tungsten : 실행 계획에 대한 코드를 짜게 해줌.

코드를 통해 의도하는 바를 설명하지만, 이것이 어떻게 동작하는지는 Catalyst Optimzer가 하는 것이다.

Unresolved Logical Plan → Logical Plan → logical optimization plan → physical plans  → cost model(계획 평가) → selected physical plan(tungsten) → RDDs

### How Catalyst optimizer works Internally

- Parsing
- Logical Plan generation
- Logical Plan optimization(Constant Folding, Predicate Pushdown, Join Reordering, Projection Pruning)
- Physical Plan generation(One or more(broadcast join, sort-merge join))
- Selection

### Dynamic Partition Pruning(DPP)

Predicate Push Down + Broadcast Hash Join

smaller(dimension) table is queried and filtered. A hash table is built as part of the filter query.</br>
작업을 하면서 최적화를 함.(at runtime)

파티션을 열기 전에 키 값을 봐서 안맞으면 파티션을 열지도 않는다.

#### Constraint

Table must be partitioned with any one of the join key columns.(파티션을 키 값에 맞게 만들어놨어야함.)</br>
Equal join에만 사용 가능.</br>
won’t apply subquery

### Spark Web UI

information from live application.</br>
you can see live data of your applications in terms of disk and memory utilization.

#### Jobs in Spark web UI

- Duration, total uptime, stage, 시간에 따른 실행 job 확인 가능

- Storage(RDD)→RDD 블록 정보

- Environment, Executors(죽은 노드가 무엇인지)

- RDD는 logical plan 중에 가장 physical에 가장 가까운 부분이다.

- Executor → 분산이 안되어있다면 → logical plan 사용

- Executor → 분산이 되어있는데도 처리가 쉽지 않다면 → hardware upgrade 필요 

### Spark History Server

review completed or running applications on the cluster.</br>
Uses the spark Event logs</br>
log는 hdfs의 namenode에 깔린다.

#### Measuring the Cost of Physical Plans

- Data Size : The number of records and size of each partition.

- Operation Type

- Data Distribution

- Join Strategy

- Number of Stages

### Adaptive Query Execution(AQE)

논리적 계획 → 실제 계획(Catalyst Optimizer)(데이터 사용 x) → AQE</br>
dynamically tunes the execution plan → based on the runtime statistics of the data</br>
데이터를 이용해서 실행 계획을 변경.</br>
principle of decoupling(분리) compute and storage layers</br>
AQE를 사용하기 전까지는 physical plan이 짜진 다음에는 수정이 불가능함.(DAG가 다짜지니까)</br>
스테이지를 잘게 쪼갠다. → query stages 생성 (런타임에)

Query Stages
- Shuffle Query Stages
- Broadcast Query Stages

파티션을 줄이고 늘리고 이거를 계속할 수도 있기 때문에 코스트가 발생할 수도 있음.</br>
최적의 판단이 아닐 가능성도 꽤 많다는 것.</br>
데이터가 주기가 있고, 고정적이고 쉽게 바뀌지 않는다면 AQE를 꺼볼 여지가 있음.

## 앞으로의 학습 방향
- gpt api를 이용한 감성 분석 코드 구성
- 전체 프로세스 통합 및 테스트
- 시각화
- Airflow 도입

## 회고
## Keep
지난 주에 팀원들과 약속했던 것처럼, 팀원들 전체가 저녁 9시 이후에 퇴근하였다. 확실히, 팀원들고 소통하며 더 빠르고 유의미한 개발을 진행할 수 있었던 것 같고, 계속 집중력을 이어갈 수 있었기에 집에서 진행할 때 필요했던 다시 집중하는 시간을 줄일 수 있게 되어 효율적이었다고 생각한다. 남은 교육 기간동안에는 계속 9시에 퇴근하는 것을 지켜야겠다.

## Problem
단순히 모든 팀원들이 열심히 노력하고 있다보니, 계획표를 짜는 것에 덜 신경썼으며, 상세한 일정을 짜지 않고 프로젝트를 진행했던 것을 깨달았다. 오늘 다노님께 계획표를 보여드릴 때 계획표가 전혀 업데이트 되지 않아, 많이 무안하기도 하였다. 프로젝트를 하면서 팀원들과 막연하게 세웠던 하루 계획을 모두 끝마치지 못한 적이 있는데, 이 부분은 상세한 일정을 짜지 않은 데에도 잘못이 있는 것 같다. 스크럼 과정에서 프로젝트 내용 뿐만 아니라 지금 어디까지 프로젝트가 진행됬는지 되돌아보고, 앞으로의 일정을 계획할 수 있도록 해야겠다.

## Try
지금까지 팀원들과 많은 고민을 하고, 디테일한 부분까지 신경쓰며 느리지만 단단하게 프로덕트를 구성하고 있었다고 생각한다. 하지만 이제는 조금 더 신속하게 개발에 집중해야할 시간이 되었다고 느껴진다. 팀원들과 고심하여 깨달은 부분을 잘 이용하여 빠르게 의사결정할 수 있다면 내일까지 빠르게 다노님 말씀처럼 전체적인 파이프라인을 신속하게 구축하고, 테스트까지 돌릴 수 있도록 하는 빠른 iteration을 시행할 수 있을 것 같다. 그 결과물을 가지고, 오류 처리, 최적화 등을 고민하며 더 나은 프로덕트를 만들기 위해 노력해야겠다.