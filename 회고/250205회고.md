## 리뷰
## 주요 진행 활동
- 5주차 미션 마무리
- 프로젝트 자료 조사
- 프로젝트 일정 수립
- 프로젝트 주제 토의

## 새롭게 알게 된 내용
python 파일(.py)에서 SparkSession을 생성하면, 스크립트 종료 후에 자동으로 세션이 종료된다. 하지만 Jupyter notebook에서는 SparkSession이 자동으로 종료되지 않는다. 왜냐하면 커널을 계속 유지하면서 다른 셀에서 spark 객체를 사용할 수 있기 때문이다. 그렇기에 python 파일을 이용한다면, spark UI를 장시간 보기 위해서는 time.sleep() method나 input()을 사용하면 된다.

cache는 반복적으로 사용되는 데이터프레임에 설정하면 되고, 한번만 호출하면 계속해서 캐시 메모리에 남기 때문에, 여러번 호출할 필요가 없다.

persist 또한 cache와 같이 동일한 데이터 셋을 여러 번 사용할 때 불필요한 재계산을 방지할 수 있도록 해주는 것이다. cache와의 차이점으로는 cache는 기본적으로 메모리에 저장하고, persist는 메모리 + 디스크에 저장할 수 있다. 그렇기에 메모리가 부족할 경우 사용할 수 있어 빅데이터에서 사용하기 좋다.

rdd에서 & 연산을 사용하지 못한다.

stage가 skip이 되는 이유는 Spark의 내부 최적화 때문이다. Spark는 동일한 데이터를 다시 읽거나 계산할 필요가 없을 때 stage를 건너뛰도록 최적화할 수 있다.

### 프로젝트
현대에서 인도 시장에 마이크로 모빌리티 비전을 발표하였다.

생각보다 자동차 업계에서는 리콜이 많이 일어나며, 이를 해결하는 것이 회사에서 중요할 것이다.

## 느낀점
Spark UI를 통해 동작 원리를 파악하려고 하다보니, Spark의 내부 최적화로 인하여 예상하지 못한 과정으로 동작이 진행되고 있는 것이 많았다. 이를 또 학습하려고 하니, 더 많은 부분을 알게 됬고, 학습량도 많아졌던 것 같다.</br>
오늘 팀원들과 토의를 하면서, 수익성과 관련한 프로젝트 주제를 가져가는 것은 텍스트 데이터 이외에 많은 것을 고려해야하는 상황이라고 판단하였고, 이에 이번 프로젝트에 적절한 주제는 아닐 것이라고 판단하였다. 오히려, 경보 시스템, 경쟁사 비교, 키워드 추출과 같은 주제로 가는 것이 더 적합하다는 생각이 들어서 이와 관련이 있는 페인 포인트를 찾아보면 좋을 것 같다.

## 앞으로의 학습 방향
Spark 내부 최적화 원리 탐구 진행.</br>
리콜 경보 시스템 프로토타입</br>
계속해서 프로젝트 아이디어 생각하기

## 회고
## Keep
팀원들과 오전에는 미션, 오후에는 프로젝트를 하기로 계획하고 진행했기에 각 활동을 할 때 온전히 집중하여 일을 진행할 수 있었던 것 같다. 프로젝트 계획도 세분화하여, 1시간은 자료 조사, 30분은 대략적인 프로젝트 일정 계획, 이후에는 각자의 아이디어를 내고 피드백을 받으며 체계적으로 시간을 잘 썼다.

## Problem
완벽하게 미션을 마무리하고 문서 정리하고자 해서, 계획한 시간 안에 미션을 마무리 짓지 못했다. 물론 미션을 완벽하게 하고 문서 정리하는 것도 중요하지만, 문서 정리까지 하는 것은 현재 나에게 우선 순위가 높지 않은 일이라고 생각한다. 다음에 계획한 활동에 지장이 가지 않기 위해서는 적당히 끊고, 시간 안에 마무리하려는 노력을 하도록 해야겠다. 꼼꼼히 하려고 하는 것이 내 성향이고, 나쁜 성향은 아니지만, 상황에 따라 유연하게 대처할 수 있도록 바뀌는 모습이 필요할 것 같다.

## Try
팀원들과 계획했던 프로젝트 일정에서의 데일리 테스크를 지키기 위해서 노력해야겠다. ideation 기간동안은 무조건 프로토타이핑 하나를 만들기로 결정하였기에 이를 꼭 지켜야겠다.