## 리뷰
## 새롭게 알게 된 내용

Docker-compose 파일을 구성하는 법을 알게 되었다.

sudo - superuser do -> 관리자 권한으로 할 수 있도록 하는 명령.

.sh - 쉘 스크립트 파일.

Hadoop jar - Hadoop의 JAR 파일 실행 명령

JAR(JAVA Archive) 파일은 JAVA로 작성된 프로그램의 패키지이며, Hadoop에서는 MapReduce 작업을 실행하는 데 사용.

Workers 파일로 지정해준 worker1, worker2를 Hadoop 클러스터에서 hadoop-worker1, hadoop-worker2로 자동 인식.

\t는 tab

Python 파일은 실행의 목적이기에 hdfs에 올리지 않고, 컨테이너 안에만 놔두고 실행만 하면 된다.

파이썬을 hadoop에서 실행할 때, file 구문을 통해 파일을 맵핑도 해주어야한다. 또한, mapper와 reducer를 실행할 때는 python3나 파이썬 파일 주소 둘 중 하나만 사용을 해야 정상적인 실행이 가능하다.

웹에서 파일을 정상적으로 올리기 위해, ssh만 루트로 들어가고 이후 user 권한으로써 hdfs에 들어가보려고 하였다. 그래서 init.sh에 ssh service start 후에 exec을 통해 user 권한으로써 들어가려고 시도했지만, ID를 확인해보니 root 권한으로써 hdfs를 들어가있는 상태였다. 아무래도 Endpoint 이후에도 DockerFile에서 이미지가 최종적으로 빌드가 되기에 그 때 권한으로 설정되어있던 root를 권한으로써 들어가지는 것 같다.
결과적으로 웹에서 파일을 올리는 것은 실패하였다.

## 느낀점
아픈 것도 좀 괜찮아지고, 여러 시행 착오를 겪다보니 하둡에 대해서 이제서야 이해되는 부분이 많은 것 같다. 하지만 아직도 각각의 구성 요소가 어떻게 작동하는지 세밀하게 파악은 되지 않고 있다. 이 부분을 추후에 미션을 진행하면서 생각해보며 학습하는 것이 좋을 것 같다.

## 앞으로의 학습 방향
내일 오전에는 Readme 파일을 작성하며, 배운 것들을 복습하고 미니 프로젝트 아이디어 떠올린 것을 구체화하여 작성해야겠다. 수업을 듣고, 남은 미션 4 ~ 6도 마저 진행해야겠다.

## 회고
## Keep
아이디어를 내는 과정에서 주저없이 내고 있다는 점이 잘하고 있는 것 같다. 이를 팀원들과 공유하며 생각을 발전해나가고, 피드백을 받으니 아이디어가 구체화되감을 느낀다.

## Problem
오늘 일찍 출근해서 해야할 업무를 계획했는데, 이외에도 해야할 일이 많아 Readme 작성에 실패했다. 이유로는 업무가 많은 것도 있지만, 글을 쓰는 게 아직도 어려워서 그런 것 같다. 글쓰는 거에 망설임을 줄일라고 계속해서 노력해야할 것 같다.

## Try
조금 더 팀 프로젝트 아이디어를 생각하는 시간을 늘리고 많이 시도하면서 미니 프로젝트를 원활히 이끌어나가야겠다.
