{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58110cc1-c52d-4aaa-bd8a-b4c3481ec3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"17.0.14\" 2025-01-21\n",
      "OpenJDK Runtime Environment Homebrew (build 17.0.14+0)\n",
      "OpenJDK 64-Bit Server VM Homebrew (build 17.0.14+0, mixed mode, sharing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.popen(\"java -version 2>&1\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad76de9-28da-4823-991e-d33c1d6e41c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mstop()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b549e21-7bff-4c4b-9e21-2b9e61ac8113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import LongType\n",
    "import os\n",
    "\n",
    "# 1️⃣ Spark 세션 생성\n",
    "spark = SparkSession.builder.appName(\"Yellow_Taxi_Anlaysis\").config(\"spark.driver.bindAddress\", \"127.0.0.1\").getOrCreate()\n",
    "\n",
    "# 2️⃣ 모든 .parquet 파일 경로 자동으로 불러오기\n",
    "directory_path = \"/Users/admin/Desktop/GitHub/softeer/과제/M4/NYC_TLC_Trip_Data/\"\n",
    "file_paths = [os.path.join(directory_path, f) for f in os.listdir(directory_path) if f.endswith(\".parquet\")]\n",
    "\n",
    "# 3️⃣ 모든 파일에 대해 형변환 처리 및 병합\n",
    "df_list = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    # 4️⃣ 각 파일 읽기\n",
    "    df = spark.read.parquet(file_path)\n",
    "    \n",
    "    # 5️⃣ 형변환 (필요한 컬럼에 대해)\n",
    "    df = df.withColumn(\"VendorID\", col(\"VendorID\").cast(LongType())) \\\n",
    "           .withColumn(\"PULocationID\", col(\"PULocationID\").cast(LongType())) \\\n",
    "           .withColumn(\"DOLocationID\", col(\"DOLocationID\").cast(LongType())) \\\n",
    "           .withColumn(\"passenger_count\", col(\"passenger_count\").cast(LongType())) \\\n",
    "           .withColumn(\"RatecodeID\", col(\"RatecodeID\").cast(LongType()))\n",
    "    \n",
    "    # 6️⃣ 변환된 DataFrame 리스트에 추가\n",
    "    df_list.append(df)\n",
    "\n",
    "# 7️⃣ 병합된 DataFrame 생성\n",
    "final_df = df_list[0]\n",
    "for df in df_list[1:]:\n",
    "    final_df = final_df.union(df)\n",
    "\n",
    "# 8️⃣ 결과 출력 (상위 5개 행)\n",
    "final_df.show(5)\n",
    "\n",
    "# 9️⃣ 필요시 저장\n",
    "# final_df.write.parquet(\"/path/to/save/final_output.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ce44d2-3ffc-433d-8c06-6aa785de05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum as spark_sum\n",
    "\n",
    "# 각 컬럼별 NULL 값 개수 확인\n",
    "null_counts_df = final_df.select(\n",
    "    [spark_sum(col(c).isNull().cast(\"int\")).alias(c) for c in final_df.columns]\n",
    ")\n",
    "\n",
    "# Pandas로 변환하여 출력\n",
    "null_counts_pd = null_counts_df.toPandas()\n",
    "null_counts_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9bdabe-32bc-4c35-ac9e-cde0d798f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a850f75-d6cd-4b0c-869d-aebf5ee42713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3️⃣ 시간 데이터 변환 (Timestamp 변환 및 trip_duration 추가)\n",
    "final_df = final_df.withColumn(\"tpep_pickup_datetime\", to_timestamp(col(\"tpep_pickup_datetime\"))) \\\n",
    "                   .withColumn(\"tpep_dropoff_datetime\", to_timestamp(col(\"tpep_dropoff_datetime\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f9303-999d-43a2-bf9f-b6277faf44b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.pandas as ps\n",
    "\n",
    "# PySpark DataFrame → Pandas API on Spark DataFrame 변환\n",
    "ps_df = final_df.pandas_api()\n",
    "\n",
    "# Pandas처럼 평균 계산 가능\n",
    "avg_trip_duration = (ps_df[\"tpep_dropoff_datetime\"]-ps_df[\"tpep_pickup_datetime\"]).mean()\n",
    "avg_trip_distance = ps_df[\"trip_distance\"].mean()\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"📌 평균 이동 시간: {avg_trip_duration:.2f} 초\")\n",
    "print(f\"📌 평균 이동 거리: {avg_trip_distance:.2f} 마일\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6782e557-5f85-449b-ad28-56677d00356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe38ffb-b7f2-46e4-91b3-5509e5d85e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ace_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19396ac-0693-4fda-9413-a4ba9f84b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import LongType, IntegerType, DoubleType, StringType\n",
    "\n",
    "# 스파크 세션 시작\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ParquetFileReader\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 벡터화된 리더 비활성화\n",
    "spark.conf.set(\"spark.sql.parquet.enableVectorizedReader\", \"false\")\n",
    "\n",
    "# 여러 파일을 읽기 전에 모든 컬럼을 String 타입으로 강제 변환\n",
    "df = spark.read.parquet(\"file:///Users/admin/Desktop/GitHub/softeer/과제/M4/NYC_TLC_Trip_Data/*.parquet\")\n",
    "\n",
    "# 모든 컬럼을 String 타입으로 변환\n",
    "for col_name in df.columns:\n",
    "    df = df.withColumn(col_name, col(col_name).cast(StringType()))\n",
    "\n",
    "# 필요한 타입으로 변환\n",
    "df = df.withColumn(\"VendorID\", col(\"VendorID\").cast(LongType()))\n",
    "df = df.withColumn(\"PULocationID\", col(\"PULocationID\").cast(LongType()))\n",
    "df = df.withColumn(\"DOLocationID\", col(\"DOLocationID\").cast(LongType()))\n",
    "df = df.withColumn(\"passenger_count\", col(\"passenger_count\").cast(IntegerType()))\n",
    "df = df.withColumn(\"fare_amount\", col(\"fare_amount\").cast(DoubleType()))\n",
    "df = df.withColumn(\"total_amount\", col(\"total_amount\").cast(DoubleType()))\n",
    "\n",
    "# 스키마 출력\n",
    "df.printSchema()\n",
    "\n",
    "# 데이터 확인 (상위 5개 행 출력)\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c784c9-8d1f-4def-8ba9-8647da104679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import LongType\n",
    "\n",
    "# 1️⃣ Spark 세션 생성\n",
    "spark = SparkSession.builder.appName(\"YellowTaxiMerge\").config(\"spark.driver.bindAddress\", \"127.0.0.1\").getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.parquet.enableVectorizedReader\", \"false\")\n",
    "\n",
    "# 2️⃣ 모든 Parquet 파일을 읽어서 하나의 DataFrame으로 병합\n",
    "file_path = \"/Users/admin/Desktop/GitHub/softeer/과제/M4/NYC_TLC_Trip_Data/*.parquet\"\n",
    "df = spark.read.option(\"mergeSchema\", \"false\").parquet(file_path)\n",
    "\n",
    "# 3️⃣ 수동으로 컬럼 타입 강제 변환 (LongType으로 변환)\n",
    "df = df.withColumn(\"VendorID\", col(\"VendorID\").cast(LongType()))\n",
    "df = df.withColumn(\"PULocationID\", col(\"PULocationID\").cast(LongType()))\n",
    "df = df.withColumn(\"DOLocationID\", col(\"DOLocationID\").cast(LongType()))\n",
    "df = df.withColumn(\"passenger_count\", col(\"passenger_count\").cast(LongType()))\n",
    "df = df.withColumn(\"payment_type\", col(\"payment_type\").cast(LongType()))\n",
    "df = df.withColumn(\"fare_amount\", col(\"fare_amount\").cast(LongType()))\n",
    "df = df.withColumn(\"extra\", col(\"extra\").cast(LongType()))\n",
    "df = df.withColumn(\"mta_tax\", col(\"mta_tax\").cast(LongType()))\n",
    "df = df.withColumn(\"tip_amount\", col(\"tip_amount\").cast(LongType()))\n",
    "df = df.withColumn(\"tolls_amount\", col(\"tolls_amount\").cast(LongType()))\n",
    "df = df.withColumn(\"improvement_surcharge\", col(\"improvement_surcharge\").cast(LongType()))\n",
    "df = df.withColumn(\"total_amount\", col(\"total_amount\").cast(LongType()))\n",
    "df = df.withColumn(\"congestion_surcharge\", col(\"congestion_surcharge\").cast(LongType()))\n",
    "df = df.withColumn(\"airport_fee\", col(\"airport_fee\").cast(LongType()))\n",
    "\n",
    "# 4️⃣ 스키마 출력\n",
    "df.printSchema()\n",
    "\n",
    "# 5️⃣ 데이터 확인 (상위 5개 행 출력)\n",
    "df.take(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd8c08-aa75-4448-9eb0-07e577c9aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# SparkSession 생성\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Schema Check\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 파일 목록 가져오기\n",
    "import glob\n",
    "\n",
    "parquet_files = glob.glob(\"/Users/admin/Desktop/GitHub/softeer/과제/M4/NYC_TLC_Trip_Data/*.parquet\")\n",
    "\n",
    "# 각 파일의 스키마 확인\n",
    "for file in parquet_files:\n",
    "    print(f\"\\n📂 파일: {file}\")\n",
    "    df = spark.read.parquet(file)\n",
    "    df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80414da-9f2c-43f9-98d2-ab8fb0be22e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# 기존 SparkContext 종료\n",
    "if SparkContext._active_spark_context:\n",
    "    SparkContext._active_spark_context.stop()\n",
    "\n",
    "# 새로운 Spark 세션 생성\n",
    "spark = SparkSession.builder.appName(\"YellowTaxiMerge\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e89866-7187-4894-a2c2-8d49828caf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "jps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f1db9c-4c8b-4e52-ba97-97ab9ea5d6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Spark 세션 생성\n",
    "spark = SparkSession.builder.appName(\"Yellow Taxi Data\").config(\"spark.driver.bindAddress\", \"127.0.0.1\").config(\"spark.driver.extraJavaOptions\", \"-Djava.security.manager=allow\").getOrCreate()\n",
    "\n",
    "# 전체 디렉터리에서 Parquet 파일 읽기\n",
    "df = spark.read.parquet(\"NYC_TLC_Trip_Data/\") \\\n",
    "    .withColumn(\"VendorID\", col(\"VendorID\").cast(\"bigint\"))  # VendorID를 bigint로 변환\n",
    "\n",
    "# 스키마 확인 및 데이터 출력\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe926c5-1b9d-42f1-b261-5bea3180190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d44e787-de90-463c-9643-340b713c5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 SparkContext가 있는 경우 종료\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "if 'spark' in locals():\n",
    "    spark.stop()\n",
    "    print(\"Existing SparkSession stopped.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa9a5e3-db0b-4637-bb97-6c5c9ae5c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 기존 SparkSession 종료\n",
    "try:\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    spark.stop()\n",
    "except Exception as e:\n",
    "    print(\"No existing SparkSession to stop:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d41c3d-f09b-43b5-8cf7-7ca323735d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Test Spark Session\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(spark)\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8906bf-cf54-4893-87bf-669d11bc3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 기존 SparkSession 및 SparkContext 종료\n",
    "try:\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    spark.stop()\n",
    "    print(\"Existing SparkSession stopped successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"No active SparkSession or failed to stop:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68590684-ed3f-4e3f-9534-42ea7f2bc246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TestApp\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"SparkSession created successfully.\")\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b594222-f425-41e5-9f10-f227d7527e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 기존 SparkSession 종료\n",
    "try:\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    spark.stop()\n",
    "    print(\"Existing SparkSession stopped.\")\n",
    "except Exception as e:\n",
    "    print(\"No active SparkSession or failed to stop:\", e)\n",
    "\n",
    "# 새로운 SparkSession 생성\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TestApp\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"SparkSession created successfully.\")\n",
    "\n",
    "# Spark 종료\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327d85a2-7b44-4cfb-9183-4ea5d0ded82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 기존 SparkSession 종료\n",
    "try:\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    spark.stop()\n",
    "    print(\"Existing SparkSession stopped.\")\n",
    "except Exception as e:\n",
    "    print(\"No active SparkSession or failed to stop:\", e)\n",
    "\n",
    "# 새로운 SparkSession 생성\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TestApp\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"SparkSession created successfully.\")\n",
    "\n",
    "# Spark 종료\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e6127-e5b8-4a65-8c12-222b42d3d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# SparkSession 생성\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TestApp\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"SparkSession created successfully.\")\n",
    "\n",
    "# Spark 종료\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ecaed-a1a0-4057-9b54-24ca0762f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TestApp\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.driver.port\", \"4041\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"SparkSession created successfully.\")\n",
    "\n",
    "# Spark 종료\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca7e888-4c30-4194-b5ab-f3c66be46150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TestApp\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.driver.port\", \"4041\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-Djava.net.preferIPv4Stack=true\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Djava.net.preferIPv4Stack=true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"SparkSession created successfully.\")\n",
    "\n",
    "# Spark 종료\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a516711-4905-4526-b1db-ca699c2cb808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TestApp\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"SparkSession created successfully.\")\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b868d1-c1cf-495f-b68f-ebd63298cfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LocalSparkTest\") \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(spark.version)\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2163ff44-8704-41f3-a029-bcc63acb4dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c957b4b-8a70-46f1-af3b-e9da2c69c179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (System)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
